{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assingment no-13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Provide an example of the concepts of Prior, Posterior, and Likelihood.\n",
    "# Ans=\n",
    "Sure! Let's consider a simple example of a medical test for a disease.\n",
    "\n",
    "Suppose we have a population in which the prevalence of the disease is 10%, meaning that 10% of the individuals have the disease, and 90% do not.\n",
    "\n",
    "Prior Probability:\n",
    "The prior probability is the initial belief or probability assigned to an event before any evidence or observation is taken into account. In this case, the prior probability would be the probability of an individual having the disease without considering any test results. Let's say we assign a prior probability of 0.10 (or 10%) to having the disease based on the population prevalence.\n",
    "\n",
    "Likelihood Probability:\n",
    "The likelihood probability represents the probability of observing a particular piece of evidence or data given a specific hypothesis or event. In our example, the likelihood probability would be the probability of obtaining a positive test result for an individual with the disease and the probability of obtaining a negative test result for an individual without the disease. Let's assume that the likelihood of a positive test result given the presence of the disease is 0.95, and the likelihood of a negative test result given the absence of the disease is 0.90.\n",
    "\n",
    "Posterior Probability:\n",
    "The posterior probability is the updated probability of an event or hypothesis after considering new evidence. It is calculated using Bayes' theorem, which combines the prior probability and the likelihood probability. In our example, the posterior probability would be the probability of an individual having the disease after taking into account the test result. Let's say we have a positive test result for an individual.\n",
    "\n",
    "Using Bayes' theorem, we can calculate the posterior probability as follows:\n",
    "Posterior probability = (Likelihood probability * Prior probability) / Evidence\n",
    "\n",
    "In this case, the evidence is the probability of obtaining a positive test result. Plugging in the values, we have:\n",
    "Posterior probability = (0.95 * 0.10) / P(positive test result)\n",
    "\n",
    "The value of P(positive test result) would depend on the test's accuracy and other factors.\n",
    "\n",
    "By calculating the posterior probability, we update our belief about an individual having the disease based on the new evidence provided by the positive test result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. What role does Bayes&#39; theorem play in the concept learning principle?\n",
    "# Ans=\n",
    "Bayes' theorem plays a fundamental role in the concept learning principle by providing a framework for updating our beliefs or knowledge about a concept based on new evidence or observations. The concept learning principle aims to infer or learn a concept based on a set of training data or examples.\n",
    "\n",
    "Bayes' theorem allows us to calculate the posterior probability of a concept given the observed data, incorporating both prior knowledge or beliefs and the likelihood of observing the data given the concept. It provides a principled way to update our initial beliefs or hypotheses in light of new evidence.\n",
    "\n",
    "In the context of concept learning, Bayes' theorem helps us make informed decisions about the most probable concept or hypothesis given the observed data. It allows us to quantify the strength of evidence in favor of different concepts and update our beliefs accordingly.\n",
    "\n",
    "By iteratively applying Bayes' theorem and updating our beliefs based on new evidence, we can refine and improve our understanding of the underlying concept being learned. This iterative process of updating beliefs and revising hypotheses forms the basis of Bayesian inference, which is widely used in machine learning and artificial intelligence to learn and generalize from data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Offer an example of how the Nave Bayes classifier is used in real life.\n",
    "# Ans\n",
    "One example of how the Naïve Bayes classifier is used in real life is in email spam filtering. The Naïve Bayes classifier is a popular choice for spam filtering due to its simplicity and effectiveness.\n",
    "\n",
    "In this scenario, the Naïve Bayes classifier is trained on a large dataset of emails that are labeled as either \"spam\" or \"non-spam\" (also known as \"ham\"). The classifier learns the statistical patterns and relationships between different words or features in the emails.\n",
    "\n",
    "When a new email arrives, the Naïve Bayes classifier applies Bayes' theorem to calculate the posterior probability of the email being spam or non-spam based on the observed features (e.g., words, presence of specific phrases, etc.). It calculates the likelihood of observing those features in spam and non-spam emails using the training data.\n",
    "\n",
    "The classifier then compares the posterior probabilities for spam and non-spam and assigns the email to the class with the higher probability. If the posterior probability of spam is higher, the email is classified as spam and can be filtered out or flagged accordingly.\n",
    "\n",
    "The Naïve Bayes classifier's strength in this application lies in its ability to handle a large number of features (words) efficiently and its ability to handle new, unseen emails effectively. Despite the simplifying assumption of independence between features, Naïve Bayes classifiers often perform well in practice for spam filtering tasks.\n",
    "\n",
    "Spam filtering is just one example of how the Naïve Bayes classifier is used. It is also employed in various other applications such as sentiment analysis, document classification, medical diagnosis, and more, where it can effectively categorize data into different classes based on observed features and prior knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Can the Nave Bayes classifier be used on continuous numeric data? If so, how can you go about\n",
    "# doing it?\n",
    "# Ans=\n",
    "Yes, the Naïve Bayes classifier can be used on continuous numeric data. However, to apply the Naïve Bayes classifier to continuous data, you need to make some assumptions or use specific techniques to handle the continuous nature of the features.\n",
    "\n",
    "One common approach is to assume that the continuous features follow a specific probability distribution, such as the Gaussian (normal) distribution. In this case, you would estimate the parameters of the Gaussian distribution (mean and variance) for each class based on the training data. Then, when classifying a new instance, you would calculate the likelihood of observing the specific feature values given the estimated distribution parameters for each class.\n",
    "\n",
    "To handle continuous data in the Naïve Bayes classifier, you would follow these steps:\n",
    "\n",
    "Prepare your dataset: Ensure that your dataset includes both the continuous feature variables and the corresponding class labels.\n",
    "\n",
    "Choose a probability distribution: Select an appropriate probability distribution that best represents the data's characteristics. The Gaussian distribution is commonly used for continuous features, but other distributions like the multinomial or kernel density estimation can also be used depending on the nature of the data.\n",
    "\n",
    "Estimate distribution parameters: For each class, estimate the distribution parameters (e.g., mean and variance for the Gaussian distribution) based on the training data. This involves calculating the mean and variance of each feature for each class.\n",
    "\n",
    "Calculate likelihood: Given a new instance with continuous feature values, calculate the likelihood of observing those feature values for each class based on the estimated distribution parameters. This is done by evaluating the probability density function of the chosen distribution.\n",
    "\n",
    "Apply Bayes' theorem: Combine the likelihood with the prior probability of each class to calculate the posterior probability using Bayes' theorem. The class with the highest posterior probability is then assigned to the instance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. What are Bayesian Belief Networks, and how do they work? What are their applications? Are they\n",
    "# capable of resolving a wide range of issues?\n",
    "# Ans=\n",
    "Bayesian Belief Networks (BBNs), also known as Bayesian Networks or Probabilistic Graphical Models, are probabilistic models that represent and reason about uncertainty and causal relationships among variables. BBNs combine graph theory and probability theory to model complex systems and make probabilistic inferences.\n",
    "\n",
    "In a BBN, variables are represented as nodes in a directed acyclic graph (DAG), where the edges between nodes indicate probabilistic dependencies or causal relationships. Each node represents a random variable, and its state depends on the states of its parent nodes. The strength of the dependencies is quantified by conditional probability tables (CPTs), which specify the probability distribution of a node given its parent nodes.\n",
    "\n",
    "To make inferences in a BBN, the network utilizes Bayes' theorem and performs probabilistic calculations. Given observed evidence, the BBN updates the probabilities of variables and computes the posterior probability distribution of the target variable(s). This allows for reasoning under uncertainty and making predictions or decisions based on the available evidence.\n",
    "\n",
    "BBNs have a wide range of applications across various domains, including:\n",
    "\n",
    "Medical Diagnosis: BBNs can be used to assist in diagnosing diseases based on patient symptoms, medical history, and test results. The network can model the dependencies between symptoms and diseases, allowing for accurate probabilistic diagnosis.\n",
    "\n",
    "Risk Assessment: BBNs can assess and manage risks in areas such as finance, insurance, and engineering. The network can model the dependencies between risk factors and estimate the likelihood of different outcomes.\n",
    "\n",
    "Decision Support: BBNs can provide decision support in complex decision-making scenarios. By modeling the causal relationships between variables and incorporating evidence, BBNs can recommend the best course of action given the available information.\n",
    "\n",
    "Image and Speech Recognition: BBNs can be used in pattern recognition tasks, such as image or speech recognition. The network can model the dependencies between features and classify or interpret patterns with uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Passengers are checked in an airport screening system to see if there is an intruder. Let I be the\n",
    "# random variable that indicates whether someone is an intruder I = 1) or not I = 0), and A be the\n",
    "# variable that indicates alarm I = 0). If an intruder is detected with probability P(A = 1|I = 1) = 0.98\n",
    "# and a non-intruder is detected with probability P(A = 1|I = 0) = 0.001, an alarm will be triggered,\n",
    "# implying the error factor. The likelihood of an intruder in the passenger population is P(I = 1) =\n",
    "# 0.00001. What are the chances that an alarm would be triggered when an individual is actually an\n",
    "# intruder?\n",
    "# Ans=\n",
    "To calculate the probability that an alarm is triggered when an individual is actually an intruder, we can use Bayes' theorem.\n",
    "\n",
    "Let's define the following variables:\n",
    "I = event of being an intruder (I = 1 for intruder, I = 0 for non-intruder)\n",
    "A = event of an alarm being triggered (A = 1 for alarm, A = 0 for no alarm)\n",
    "\n",
    "We are given the following probabilities:\n",
    "P(A = 1|I = 1) = 0.98 (Probability of an alarm being triggered given that the person is an intruder)\n",
    "P(A = 1|I = 0) = 0.001 (Probability of an alarm being triggered given that the person is not an intruder)\n",
    "P(I = 1) = 0.00001 (Probability of a randomly selected person being an intruder)\n",
    "\n",
    "We want to find P(I = 1|A = 1), which is the probability of a person being an intruder given that an alarm is triggered.\n",
    "\n",
    "Using Bayes' theorem:\n",
    "P(I = 1|A = 1) = (P(A = 1|I = 1) * P(I = 1)) / P(A = 1)\n",
    "\n",
    "To find P(A = 1), we can use the law of total probability:\n",
    "P(A = 1) = P(A = 1|I = 1) * P(I = 1) + P(A = 1|I = 0) * P(I = 0)\n",
    "\n",
    "Let's calculate the probabilities:\n",
    "P(A = 1) = (0.98 * 0.00001) + (0.001 * (1 - 0.00001))\n",
    "= 0.0000098 + 0.000000999\n",
    "= 0.000010799\n",
    "\n",
    "Now we can calculate P(I = 1|A = 1):\n",
    "P(I = 1|A = 1) = (0.98 * 0.00001) / 0.000010799\n",
    "= 0.0000098 / 0.000010799\n",
    "≈ 0.906\n",
    "\n",
    "Therefore, the chances that an alarm would be triggered when an individual is actually an intruder is approximately 0.906, or 90.6%.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. An antibiotic resistance test (random variable T) has 1% false positives (i.e., 1% of those who are\n",
    "# not immune to an antibiotic display a positive result in the test) and 5% false negatives (i.e., 1% of\n",
    "# those who are not resistant to an antibiotic show a positive result in the test) (i.e. 5 percent of those\n",
    "# actually resistant to an antibiotic test negative). Assume that 2% of those who were screened were\n",
    "# antibiotic-resistant. Calculate the likelihood that a person who tests positive is actually immune\n",
    "# (random variable D).\n",
    "# Ans=\n",
    "To calculate the likelihood that a person who tests positive is actually immune (antibiotic-resistant), we can use Bayes' theorem.\n",
    "\n",
    "Let's define the following variables:\n",
    "D = event of being immune (D = 1 for immune, D = 0 for not immune)\n",
    "T = event of a positive test result (T = 1 for positive, T = 0 for negative)\n",
    "\n",
    "We are given the following probabilities:\n",
    "P(T = 1|D = 0) = 0.01 (Probability of a positive test result given that the person is not immune)\n",
    "P(T = 0|D = 1) = 0.05 (Probability of a negative test result given that the person is immune)\n",
    "P(D = 1) = 0.02 (Probability of a randomly selected person being immune)\n",
    "\n",
    "We want to find P(D = 1|T = 1), which is the likelihood of a person being immune given a positive test result.\n",
    "\n",
    "Using Bayes' theorem:\n",
    "P(D = 1|T = 1) = (P(T = 1|D = 1) * P(D = 1)) / P(T = 1)\n",
    "\n",
    "To find P(T = 1), we can use the law of total probability:\n",
    "P(T = 1) = P(T = 1|D = 1) * P(D = 1) + P(T = 1|D = 0) * P(D = 0)\n",
    "\n",
    "Let's calculate the probabilities:\n",
    "P(T = 1) = (0.05 * 0.02) + (0.01 * (1 - 0.02))\n",
    "= 0.001 + 0.0098\n",
    "= 0.0108\n",
    "\n",
    "Now we can calculate P(D = 1|T = 1):\n",
    "P(D = 1|T = 1) = (0.05 * 0.02) / 0.0108\n",
    "= 0.001 / 0.0108\n",
    "≈ 0.0926\n",
    "\n",
    "Therefore, the likelihood that a person who tests positive is actually immune (antibiotic-resistant) is approximately 0.0926, or 9.26%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. In order to prepare for the test, a student knows that there will be one question in the exam that\n",
    "# is either form A, B, or C. The chances of getting an A, B, or C on the exam are 30 percent, 20%, and\n",
    "# 50 percent, respectively. During the planning, the student solved 9 of 10 type A problems, 2 of 10\n",
    "# type B problems, and 6 of 10 type C problems.\n",
    "\n",
    "# 1. What is the likelihood that the student can solve the exam problem?\n",
    "\n",
    "# 2. Given the student&#39;s solution, what is the likelihood that the problem was of form A?\n",
    "# Ans=\n",
    "To calculate the likelihood that the student can solve the exam problem and the likelihood that the problem was of form A given the student's solution, we can use Bayes' theorem.\n",
    "\n",
    "Let's define the following variables:\n",
    "E = event of the student being able to solve the exam problem (E = 1 for able to solve, E = 0 for unable to solve)\n",
    "A = event of the problem being of form A (A = 1 for form A, A = 0 for not form A)\n",
    "\n",
    "We are given the following probabilities:\n",
    "P(E = 1|A = 1) = 9/10 (Probability of being able to solve the problem given it is of form A)\n",
    "P(E = 1|A = 0) = 2/10 (Probability of being able to solve the problem given it is not of form A)\n",
    "P(A = 1) = 0.30 (Probability of the problem being of form A)\n",
    "\n",
    "To calculate the likelihood that the student can solve the exam problem (P(E = 1)), we can use the law of total probability:\n",
    "P(E = 1) = P(E = 1|A = 1) * P(A = 1) + P(E = 1|A = 0) * P(A = 0)\n",
    "P(E = 1) = (9/10 * 0.30) + (2/10 * (1 - 0.30))\n",
    "= 0.27 + 0.14\n",
    "= 0.41\n",
    "\n",
    "Therefore, the likelihood that the student can solve the exam problem is 0.41, or 41%.\n",
    "\n",
    "To calculate the likelihood that the problem was of form A given the student's solution (P(A = 1|E = 1)), we can use Bayes' theorem:\n",
    "P(A = 1|E = 1) = (P(E = 1|A = 1) * P(A = 1)) / P(E = 1)\n",
    "P(A = 1|E = 1) = (9/10 * 0.30) / 0.41\n",
    "= 0.27 / 0.41\n",
    "≈ 0.659\n",
    "\n",
    "Therefore, the likelihood that the problem was of form A given the student's solution is approximately 0.659, or 65.9%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. A bank installs a CCTV system to track and photograph incoming customers. Despite the constant\n",
    "# influx of customers, we divide the timeline into 5 minute bins. There may be a customer coming into\n",
    "# the bank with a 5% chance in each 5-minute time period, or there may be no customer (again, for\n",
    "# simplicity, we assume that either there is 1 customer or none, not the case of multiple customers). If\n",
    "\n",
    "# there is a client, the CCTV will detect them with a 99 percent probability. If there is no customer, the\n",
    "# camera can take a false photograph with a 10% chance of detecting movement from other objects.\n",
    "\n",
    "# 1. How many customers come into the bank on a daily basis (10 hours)?\n",
    "\n",
    "# 2. On a daily basis, how many fake photographs (photographs taken when there is no\n",
    "# customer) and how many missed photographs (photographs taken when there is a customer) are\n",
    "# there?\n",
    "\n",
    "# 3. Explain likelihood that there is a customer if there is a photograph?\n",
    "\n",
    "# Ans\n",
    "\n",
    "To answer the questions, let's define the following variables:\n",
    "C = event of a customer coming into the bank in a 5-minute time period (C = 1 for customer, C = 0 for no customer)\n",
    "D = event of the CCTV detecting a customer (D = 1 for detection, D = 0 for no detection)\n",
    "\n",
    "We are given the following probabilities:\n",
    "P(C = 1) = 0.05 (Probability of a customer coming into the bank in a 5-minute time period)\n",
    "P(D = 1 | C = 1) = 0.99 (Probability of detection if there is a customer)\n",
    "P(D = 1 | C = 0) = 0.10 (Probability of detection when there is no customer)\n",
    "\n",
    "To calculate the number of customers coming into the bank on a daily basis (10 hours), we need to determine the number of 5-minute time periods in 10 hours and multiply it by the probability of a customer coming in each time period:\n",
    "Number of 5-minute time periods in 10 hours = (10 hours * 60 minutes) / 5 minutes = 120\n",
    "Number of customers coming into the bank on a daily basis = P(C = 1) * Number of 5-minute time periods\n",
    "= 0.05 * 120\n",
    "= 6 customers\n",
    "\n",
    "Therefore, on a daily basis, approximately 6 customers come into the bank.\n",
    "\n",
    "To calculate the number of fake photographs and missed photographs on a daily basis, we need to consider the cases when there is no customer (C = 0) and when there is a customer (C = 1).\n",
    "Number of fake photographs (photographs taken when there is no customer) on a daily basis = P(C = 0) * P(D = 1 | C = 0) * Number of 5-minute time periods\n",
    "= (1 - P(C = 1)) * P(D = 1 | C = 0) * 120\n",
    "= (1 - 0.05) * 0.10 * 120\n",
    "= 0.95 * 0.10 * 120\n",
    "= 11.4\n",
    "\n",
    "Number of missed photographs (photographs taken when there is a customer) on a daily basis = P(C = 1) * (1 - P(D = 1 | C = 1)) * Number of 5-minute time periods\n",
    "= 0.05 * (1 - 0.99) * 120\n",
    "= 0.05 * 0.01 * 120\n",
    "= 0.06\n",
    "\n",
    "Therefore, on a daily basis, there are approximately 11.4 fake photographs and 0.06 missed photographs.\n",
    "\n",
    "The likelihood that there is a customer if there is a photograph (P(C = 1 | D = 1)) can be calculated using Bayes' theorem:\n",
    "P(C = 1 | D = 1) = (P(D = 1 | C = 1) * P(C = 1)) / P(D = 1)\n",
    "\n",
    "To calculate P(D = 1), we need to consider both cases: customer (C = 1) and no customer (C = 0).\n",
    "\n",
    "P(D = 1) = P(D = 1 | C = 1) * P(C = 1) + P(D = 1 | C = 0) * P(C = 0)\n",
    "= 0.99 * 0.05 + 0.10 * 0.95\n",
    "= 0.0495 + 0.095\n",
    "= 0.1445"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Create the conditional probability table associated with the node Won Toss in the Bayesian Belief\n",
    "# network to represent the conditional independence assumptions of the Nave Bayes classifier for the\n",
    "# match winning prediction problem in Section 6.4.4.\n",
    "# Ans=\n",
    "To create the conditional probability table (CPT) for the node \"Won Toss\" in the Bayesian Belief Network (BBN) representing the Naive Bayes classifier for match winning prediction, we need to make the assumption that the outcome of \"Won Toss\" is conditionally independent of all other variables given the class variable (e.g., \"Match Result\").\n",
    "\n",
    "Let's assume that the class variable \"Match Result\" has two possible values: \"Win\" and \"Loss\". And the variable \"Won Toss\" has two possible values: \"Yes\" and \"No\".\n",
    "\n",
    "The CPT for the node \"Won Toss\" would look like:\n",
    "\n",
    "java\n",
    "Copy code\n",
    "Match Result  |   Won Toss = Yes   |   Won Toss = No\n",
    "-----------------------------------------------------\n",
    "Win           |     P(Won Toss = Yes | Win)     |     P(Won Toss = No | Win)\n",
    "Loss          |     P(Won Toss = Yes | Loss)    |     P(Won Toss = No | Loss)\n",
    "You would need to fill in the conditional probabilities based on the training data or domain knowledge. Each entry in the CPT represents the probability of the corresponding combination of variables.\n",
    "\n",
    "For example, if you have historical data that shows that the team that won the toss has a higher probability of winning the match, you might have the following probabilities:\n",
    "\n",
    "markdown\n",
    "Copy code\n",
    "Match Result  |   Won Toss = Yes   |   Won Toss = No\n",
    "-----------------------------------------------------\n",
    "Win           |         0.8                  |         0.2\n",
    "Loss          |         0.3                  |         0.7\n",
    "These probabilities are just hypothetical examples and you would need to determine them based on your specific data or domain knowledge.\n",
    "\n",
    "Note that the Naive Bayes classifier assumes conditional independence between the predictor variables (such as \"Won Toss\") given the class variable (\"Match Result\"), which allows us to factorize the joint probability distribution into simpler conditional probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
